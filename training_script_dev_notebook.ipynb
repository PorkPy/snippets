{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c00a5495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:03:18: Getting Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>master_case_number</th>\n",
       "      <th>target</th>\n",
       "      <th>prev_rlq_percent_comp</th>\n",
       "      <th>cur_rlq_percent_comp</th>\n",
       "      <th>curr_rlq_paid</th>\n",
       "      <th>curr_rlq_due</th>\n",
       "      <th>direct_payment</th>\n",
       "      <th>change_income_when</th>\n",
       "      <th>full_year_liability_per_case</th>\n",
       "      <th>pwc_age_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>compliance_notification_count</th>\n",
       "      <th>liability_due_4</th>\n",
       "      <th>liability_due_median</th>\n",
       "      <th>end_employer_when</th>\n",
       "      <th>sum_qc_age_group_3</th>\n",
       "      <th>standing_order_pmop</th>\n",
       "      <th>no_action_when</th>\n",
       "      <th>sr_open</th>\n",
       "      <th>credit_1</th>\n",
       "      <th>liability_allocated_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-529368335</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-4608924138</td>\n",
       "      <td>1</td>\n",
       "      <td>114.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8548.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>3080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-6652411617</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-5723622145</td>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2727.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-5019975231</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>1-41749522344</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2599.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>1-73415578763</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6658.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>1-66572836486</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>1-6168485889</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7136.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>1-50110602613</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2588.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6942 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     master_case_number  target  prev_rlq_percent_comp  cur_rlq_percent_comp  \\\n",
       "0           1-529368335       1                   53.0                  96.0   \n",
       "1          1-4608924138       1                  114.0                 116.0   \n",
       "2          1-6652411617       1                  126.0                 117.0   \n",
       "3          1-5723622145       1                  102.0                 116.0   \n",
       "4          1-5019975231       1                  110.0                  94.0   \n",
       "...                 ...     ...                    ...                   ...   \n",
       "6937      1-41749522344       0                   81.0                 106.0   \n",
       "6938      1-73415578763       0                   93.0                 100.0   \n",
       "6939      1-66572836486       0                   88.0                  96.0   \n",
       "6940       1-6168485889       0                   70.0                 138.0   \n",
       "6941      1-50110602613       0                  104.0                 104.0   \n",
       "\n",
       "      curr_rlq_paid  curr_rlq_due  direct_payment  change_income_when  \\\n",
       "0             388.0         406.0               0                 0.0   \n",
       "1            2413.0        2084.0               0                 0.0   \n",
       "2             675.0         579.0               0                 0.0   \n",
       "3             777.0         672.0               0                 0.0   \n",
       "4             282.0         300.0               0                 0.0   \n",
       "...             ...           ...             ...                 ...   \n",
       "6937         1113.0        1051.0               0                10.0   \n",
       "6938         1664.0        1660.0               0                 0.0   \n",
       "6939          215.0         223.0               0                 0.0   \n",
       "6940         1170.0         849.0               0                 0.0   \n",
       "6941          669.0         645.0               0                 0.0   \n",
       "\n",
       "      full_year_liability_per_case  pwc_age_diff  ...  \\\n",
       "0                           1687.0             0  ...   \n",
       "1                           8548.0             0  ...   \n",
       "2                           2321.0             0  ...   \n",
       "3                           2727.0             0  ...   \n",
       "4                           1215.0             0  ...   \n",
       "...                            ...           ...  ...   \n",
       "6937                        2599.0             0  ...   \n",
       "6938                        6658.0             0  ...   \n",
       "6939                         971.0             0  ...   \n",
       "6940                        7136.0             0  ...   \n",
       "6941                        2588.0             0  ...   \n",
       "\n",
       "      compliance_notification_count  liability_due_4  liability_due_median  \\\n",
       "0                               0.0             32.0                  32.0   \n",
       "1                               0.0            726.0                 495.0   \n",
       "2                               0.0             45.0                  45.0   \n",
       "3                               0.0            232.0                 224.0   \n",
       "4                               0.0             98.0                  96.0   \n",
       "...                             ...              ...                   ...   \n",
       "6937                            0.0             89.0                  89.0   \n",
       "6938                            0.0            128.0                 128.0   \n",
       "6939                            0.0             19.0                  19.0   \n",
       "6940                            0.0            282.0                 278.0   \n",
       "6941                            1.0             50.0                  50.0   \n",
       "\n",
       "      end_employer_when  sum_qc_age_group_3  standing_order_pmop  \\\n",
       "0                   0.0                 0.0                    1   \n",
       "1                   0.0                 1.0                    1   \n",
       "2                  14.0                 0.0                    0   \n",
       "3                   0.0                 0.0                    0   \n",
       "4                   0.0                 1.0                    1   \n",
       "...                 ...                 ...                  ...   \n",
       "6937                0.0                 0.0                    0   \n",
       "6938                0.0                 0.0                    0   \n",
       "6939                0.0                 0.0                    0   \n",
       "6940                0.0                 1.0                    0   \n",
       "6941                0.0                 0.0                    0   \n",
       "\n",
       "      no_action_when  sr_open  credit_1  liability_allocated_sum  \n",
       "0                0.0      1.0     200.0                     97.0  \n",
       "1                0.0      0.0     363.0                   3080.0  \n",
       "2                0.0      1.0      92.0                    134.0  \n",
       "3                0.0      0.0     142.0                   1606.0  \n",
       "4                0.0      0.0     103.0                    798.0  \n",
       "...              ...      ...       ...                      ...  \n",
       "6937             0.0      2.0      50.0                    695.0  \n",
       "6938             0.0      0.0     154.0                   1174.0  \n",
       "6939             0.0      0.0      19.0                    152.0  \n",
       "6940            87.0      0.0     298.0                    849.0  \n",
       "6941             0.0      0.0     268.0                    149.0  \n",
       "\n",
       "[6942 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:03:19: Defining Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "WARNING:sagemaker.interactive_apps.base_interactive_app:NOTEBOOK_METADATA_FILE detected but failed to get valid domain and user from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:03:19: fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-10-16-13-03-19-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-10-16 13:03:19 Starting - Starting the training job......\n",
      "2023-10-16 13:03:57 Starting - Preparing the instances for training......\n",
      "2023-10-16 13:05:00 Downloading - Downloading input data...\n",
      "2023-10-16 13:05:51 Training - Training image download completed. Training in progress.....\u001b[34m[2023-10-16 13:06:14.842 ip-10-0-170-92.eu-west-2.compute.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-16 13:06:14.905 ip-10-0-170-92.eu-west-2.compute.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:15:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:15:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:15:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:15:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:15:INFO] Module custom_eval does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:15:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:15:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:15:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: custom-eval\n",
      "  Building wheel for custom-eval (setup.py): started\n",
      "  Building wheel for custom-eval (setup.py): finished with status 'done'\n",
      "  Created wheel for custom-eval: filename=custom_eval-1.0.0-py2.py3-none-any.whl size=4519 sha256=bfff55ebbc5304da8b7330073a5db8ff5b3a8ade6e391f3ff8c23bd1345b11a8\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-u5sk8s13/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built custom-eval\u001b[0m\n",
      "\u001b[34mInstalling collected packages: custom-eval\u001b[0m\n",
      "\u001b[34mSuccessfully installed custom-eval-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:17:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:17:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:17:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eval_metric\": \"auc\",\n",
      "        \"num_round\": 10,\n",
      "        \"objective\": \"binary:logistic\",\n",
      "        \"rate_drop\": 0.3,\n",
      "        \"seed\": 42,\n",
      "        \"tweedie_variance_power\": 1.4\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2023-10-16-13-03-19-700\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://cmg-sagemaker-compliance-cases-data/sagemaker-xgboost-2023-10-16-13-03-19-700/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"custom_eval\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"custom_eval.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eval_metric\":\"auc\",\"num_round\":10,\"objective\":\"binary:logistic\",\"rate_drop\":0.3,\"seed\":42,\"tweedie_variance_power\":1.4}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=custom_eval.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=custom_eval\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://cmg-sagemaker-compliance-cases-data/sagemaker-xgboost-2023-10-16-13-03-19-700/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eval_metric\":\"auc\",\"num_round\":10,\"objective\":\"binary:logistic\",\"rate_drop\":0.3,\"seed\":42,\"tweedie_variance_power\":1.4},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2023-10-16-13-03-19-700\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://cmg-sagemaker-compliance-cases-data/sagemaker-xgboost-2023-10-16-13-03-19-700/source/sourcedir.tar.gz\",\"module_name\":\"custom_eval\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"custom_eval.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eval_metric\",\"auc\",\"--num_round\",\"10\",\"--objective\",\"binary:logistic\",\"--rate_drop\",\"0.3\",\"--seed\",\"42\",\"--tweedie_variance_power\",\"1.4\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_METRIC=auc\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=10\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=binary:logistic\u001b[0m\n",
      "\u001b[34mSM_HP_RATE_DROP=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=42\u001b[0m\n",
      "\u001b[34mSM_HP_TWEEDIE_VARIANCE_POWER=1.4\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m custom_eval --eval_metric auc --num_round 10 --objective binary:logistic --rate_drop 0.3 --seed 42 --tweedie_variance_power 1.4\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34m*********************************************************\u001b[0m\n",
      "\u001b[34mCheck if data exists at the paths\u001b[0m\n",
      "\u001b[34mtraining data None validation data None\u001b[0m\n",
      "\u001b[34mTraining data not found at /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mValidation data not found at /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[13:06:18] WARNING: ../src/data/data.cc:759: No format parameter is provided in input uri.  Choosing default parser in dmlc-core.  Consider providing a uri parameter like: filename?format=csv\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/custom_eval.py\", line 67, in <module>\n",
      "    dtrain = xgb.DMatrix('/opt/ml/input/data/train')\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 616, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/data.py\", line 766, in dispatch_data_backend\n",
      "    return _from_uri(data, missing, feature_names, feature_types)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/data.py\", line 681, in _from_uri\n",
      "    _check_call(_LIB.XGDMatrixCreateFromFile(c_str(data),\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/xgboost/core.py\", line 218, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34mxgboost.core.XGBoostError: [13:06:18] ../src/data/data.cc:765: Encountered parser error:\u001b[0m\n",
      "\u001b[34m[13:06:18] ../dmlc-core/src/io/input_split_base.cc:173: Check failed: files_.size() != 0U (0 vs. 0) : Cannot find any files that matches the URI pattern /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x572219) [0x7f2b60ea7219]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x5751af) [0x7f2b60eaa1af]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x57523e) [0x7f2b60eaa23e]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x563f60) [0x7f2b60e98f60]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x56453e) [0x7f2b60e9953e]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x544830) [0x7f2b60e79830]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x524763) [0x7f2b60e59763]\n",
      "  [bt] (7) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x117e34) [0x7f2b60a4ce34]\n",
      "  [bt] (8) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGDMatrixCreateFromFile+0xd2) [0x7f2b609d5b12]\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x1135c9) [0x7f2b60a485c9]\n",
      "  [bt] (1) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(+0x659fa) [0x7f2b6099a9fa]\n",
      "  [bt] (2) /miniconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.so(XGDMatrixCreateFromFile+0xd2) [0x7f2b609d5b12]\n",
      "  [bt] (3) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f2bbdaf39dd]\n",
      "  [bt] (4) /miniconda3/lib/python3.8/lib-dynload/../../libffi.so.7(+0x6067) [0x7f2bbdaf3067]\n",
      "  [bt] (5) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(_ctypes_callproc+0x319) [0x7f2bbc9d11e9]\n",
      "  [bt] (6) /miniconda3/lib/python3.8/lib-dynload/_ctypes.cpython-38-x86_64-linux-gnu.so(+0x13c95) [0x7f2bbc9d1c95]\n",
      "  [bt] (7) /miniconda3/bin/python3(_PyObject_MakeTpCall+0x3bf) [0x55781b4ca13f]\n",
      "  [bt] (8) /miniconda3/bin/python3(_PyEval_EvalFrameDefault+0x5434) [0x55781b574dd4]\u001b[0m\n",
      "\u001b[34m[2023-10-16:13:06:18:ERROR] ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/miniconda3/bin/python3 -m custom_eval --eval_metric auc --num_round 10 --objective binary:logistic --rate_drop 0.3 --seed 42 --tweedie_variance_power 1.4\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-10-16 13:06:39 Uploading - Uploading generated training model\n",
      "2023-10-16 13:06:39 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-xgboost-2023-10-16-13-03-19-700: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/miniconda3/bin/python3 -m custom_eval --eval_metric auc --num_round 10 --objective binary:logistic --rate_drop 0.3 --seed 42 --tweedie_variance_power 1.4\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 385\u001b[0m\n\u001b[1;32m    382\u001b[0m xgb \u001b[38;5;241m=\u001b[39m model(bucket, file_path)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m## Fit model to data\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m xgb \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_input_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_input_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m## Evaluate model and if precision and recall both > 0.7, then save to S3.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m evaluate_model_and_upload(xgb, validation_data, bucket)\n",
      "Cell \u001b[0;32mIn[14], line 249\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(xgb, s3_input_train, s3_input_test)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_model\u001b[39m(xgb, s3_input_train, s3_input_test):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow(tz)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: fitting model\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m## Print status Message to logs.\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_input_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_input_test\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, job_name=job_name)\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xgb\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py:1310\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1310\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/estimator.py:2580\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:4849\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   4828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4829\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   4830\u001b[0m \n\u001b[1;32m   4831\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4847\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   4848\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4849\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboto_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:6760\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(boto_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   6757\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   6759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 6760\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6761\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   6762\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py:6813\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   6807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   6808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   6809\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6810\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6811\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6812\u001b[0m     )\n\u001b[0;32m-> 6813\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   6814\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6815\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6816\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6817\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-xgboost-2023-10-16-13-03-19-700: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/miniconda3/bin/python3 -m custom_eval --eval_metric auc --num_round 10 --objective binary:logistic --rate_drop 0.3 --seed 42 --tweedie_variance_power 1.4\", exit code: 1"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Changes:\n",
    "    latest object key is not getting latest object during this test. \n",
    "    Instead it is getting specific key to training data.\n",
    "    \n",
    "    commented out installs\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'eu-west-2'\n",
    "\n",
    "\n",
    "# import subprocess\n",
    "# import sys\n",
    "# # Install sagemaker and xgboost as not present \n",
    "# subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker', 'xgboost'])\n",
    "\n",
    "\n",
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import io\n",
    "import sagemaker, boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Create a timezone object for London\n",
    "tz = pytz.timezone('Europe/London')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Script to train XGBoost model.\n",
    "Code fetches data from specified S3 location, cleans data, saves to S3 training data location,\n",
    "initiates XGBoost container, trains model and saves model back into S3 for \n",
    "future deployment\n",
    "\"\"\"\n",
    "\n",
    "## get data, Duh!\n",
    "\n",
    "from typing import Tuple\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Create a timezone object for London\n",
    "tz = pytz.timezone('Europe/London')\n",
    "\n",
    "def get_data(bucket, prefix, file_path) -> Tuple[DataFrame, DataFrame, DataFrame]:\n",
    "    \n",
    "    \"\"\"\n",
    "    This function gets the latest training-data file added to the training-data location in S3.\n",
    "    This is the same location that triggers the training pipeline which executes this script when a new \n",
    "    file is uploaded to S3. The function then returns a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        bucket: The name of the S3 bucket to fetch and deposit data, currently 'cmg-sagemaker-compliance-cases-data'.\n",
    "        prefix: The name of folder where the training data is stored, currently 'training_data'.\n",
    "        file_path: The name of the folder in S3 for saving temp pre-processing data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataFrame, DataFrame, DataFrame]: training_data, testing_data, validation_data.\n",
    "        + makes available training and validation data in S3.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"{datetime.now(tz).strftime('%H:%M:%S')}: Getting Data\", flush=True) ## Print status Message to logs.\n",
    "    \n",
    "    s3 = boto3.resource('s3')     ## Create an Amazon S3 resource object.\n",
    "    s3_bucket = s3.Bucket(bucket) ## Create a bucket object for a specific S3 bucket.\n",
    "\n",
    "    ## Get a list of objects in the bucket.\n",
    "    objects = list(s3_bucket.objects.filter(Prefix=prefix))\n",
    "\n",
    "    ## Sort the objects by last modified date.\n",
    "    objects.sort(key=lambda obj: obj.last_modified, reverse=True)\n",
    "\n",
    "    ## Get the key of the latest object.\n",
    "    latest_object_key = 'trainingBucket/April-Dataset_v3.csv' # objects[0].key\n",
    "    \n",
    "    ## Retriev CSV file from S3 bucket and load it into a pandas DataFrame.\n",
    "    s3 = boto3.client('s3') ## Change s3 object to client interface.\n",
    "    obj = s3.get_object(Bucket= bucket, Key= latest_object_key) ## Get object from S3.\n",
    "    df = pd.read_csv(io.BytesIO(obj['Body'].read())) ## Convert object to Pandas DataFrame\n",
    "    \n",
    "    ## Select features needed for model.\n",
    "    df = df[['master_case_number',\n",
    "             'target',\n",
    "\n",
    "           'prev_rlq_percent_comp',\n",
    "           'cur_rlq_percent_comp',\n",
    "           'curr_rlq_paid',\n",
    "           'curr_rlq_due',\n",
    "\n",
    "         'direct_payment',\n",
    "         'change_income_when',\n",
    "         'full_year_liability_per_case',\n",
    "         'pwc_age_diff',\n",
    "         'dfb_failure_when',\n",
    "         'deo',\n",
    "         'credit_4',\n",
    "         'dfb_failure_duration',\n",
    "         'debit_std',\n",
    "         'liability_allocated_1',\n",
    "         'call_inbound_pwc_int_cnt',\n",
    "         'annual_review_count',\n",
    "         'unemployed',\n",
    "         'out_of_arrears_when',\n",
    "         'deo_when',\n",
    "         'liability_allocated_median',\n",
    "         'compliance_notification_count',\n",
    "         'liability_due_4',\n",
    "         'liability_due_median',\n",
    "         'end_employer_when',\n",
    "         'sum_qc_age_group_3',\n",
    "         'standing_order_pmop',\n",
    "         'no_action_when',\n",
    "         'sr_open',\n",
    "         'credit_1',\n",
    "         'liability_allocated_sum']]\n",
    "            \n",
    "    ## Split data into training, testing and validation datasets.\n",
    "    training_data, testing_data, validation_data = train_test_split(df, bucket, file_path)\n",
    "    \n",
    "    #print(f'{datetime.now()}: XGBoost ', flush=True) ## Print status Message to logs.\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "    return training_data, testing_data, validation_data\n",
    "\n",
    "def train_test_split(df, bucket, file_path):\n",
    "    \n",
    "    \n",
    "    ## create 'target' object to move target column to start of the data.\n",
    "    target = df.target\n",
    "    ## remove unnecessary features.\n",
    "    df = df.drop(columns=[\n",
    "                            'master_case_number',\n",
    "                            'target'])\n",
    "    \n",
    "    ## Make 'Target' first column.\n",
    "    df = pd.concat([target, df], axis=1)\n",
    "\n",
    "    ## split data into training, test and validation.\n",
    "    np.random.seed(42)\n",
    "    train_data, test_data, validation_data = np.split(\n",
    "        df.sample(frac=1, random_state=42),\n",
    "        [int(0.8 * len(df)), int(0.9 * len(df))], ## slices = train:80%, test:10%, val:10% \n",
    "    )\n",
    "    \n",
    "    \n",
    "    ## upload cleaned data to S3.\n",
    "    upload(train_data, bucket, file_path, 'temp_train.csv') \n",
    "    upload(test_data, bucket,  file_path, 'temp_test.csv') \n",
    "\n",
    "    return train_data, test_data, validation_data\n",
    "\n",
    "\n",
    "def upload(df, bucket, file_path, file_name):\n",
    "    ## Keep df as StringIO object in memory, reducing need for large instance storage.\n",
    "    csv_buffer = io.StringIO()\n",
    "    df.to_csv(csv_buffer, header=False, index=False)\n",
    "    boto3.client('s3').put_object(Body=csv_buffer.getvalue(), Bucket=bucket, Key=file_path+'/'+file_name) \n",
    "\n",
    "    \n",
    "def get_data_pointer(bucket, file_path):\n",
    "    ## Create pointer objects that direct the estimator to the data in S3.\n",
    "    s3_input_train = TrainingInput(\n",
    "        s3_data=\"s3://{}/{}/temp_train\".format(bucket, file_path), content_type=\"csv\", input_mode='Pipe'\n",
    "    ) ## pipe_mode streams the data from S3 to the training script reducing the amount of memory required.\n",
    "\n",
    "    ## Define testing input to algorithm.\n",
    "    s3_input_test = TrainingInput(\n",
    "        s3_data=\"s3://{}/{}/temp_test\".format(bucket, file_path), content_type=\"csv\", input_mode='Pipe'\n",
    "    ) \n",
    "    return s3_input_train, s3_input_test\n",
    "\n",
    "\n",
    "\n",
    "def model(bucket, file_path):\n",
    "    \n",
    "    print(f\"{datetime.now(tz).strftime('%H:%M:%S')}: Defining Model\", flush=True)\n",
    "    \n",
    "    \"\"\"Fetch the AWS XGBoost algorithm container. \n",
    "    Define some container parameters. \n",
    "    Set some estimator hyper-parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## set container parameters\n",
    "    #from sagemaker.debugger import Rule, rule_configs\n",
    "    \n",
    "    ## this just needs defining for some reason.\n",
    "    role = get_execution_role()\n",
    "\n",
    "    # Sagemaker session\n",
    "    sess = sagemaker.Session() #\"\"\"prob dont need this now\"\"\"\n",
    "\n",
    "    ## get xgboost container\n",
    "    container = sagemaker.image_uris.retrieve(\"xgboost\", sess.boto_region_name, \"1.5-1\")\n",
    "\n",
    "#     ## Create a SageMaker XGBoost Estimator\n",
    "#     xgb = sagemaker.estimator.Estimator(\n",
    "#         image_uri=container,\n",
    "#         entry_point=\"custom_eval.py\",  ## Path to your custom training script with custom eval\n",
    "#         #framework_version=\"1.5-1\",\n",
    "#         role=role,\n",
    "#         instance_count=1,\n",
    "#         instance_type='ml.p3.2xlarge',\n",
    "#         output_path=\"s3://cmg-sagemaker-compliance-cases-data/model_dev_pipeline/model_artefacts/\",\n",
    "#     )\n",
    "    \n",
    "    ## define estimator parameters.\n",
    "    xgb = sagemaker.estimator.Estimator(\n",
    "        container,\n",
    "        role,\n",
    "        instance_count=1,\n",
    "        instance_type='ml.p3.2xlarge',\n",
    "        output_path=\"s3://cmg-sagemaker-compliance-cases-data/model_dev_pipeline/model_artefacts/\",\n",
    "        sagemaker_session=sess,\n",
    "        #rules=[Rule.sagemaker(rule_configs.create_xgboost_report())],\n",
    "    )\n",
    "\n",
    "    ## set basic estimator hyper-parameters.\n",
    "    ## XGB specific hyps will be searched for using hyperparameterTuner.\n",
    "    xgb.set_hyperparameters(\n",
    "                            eval_metric=\"auc\",\n",
    "                            objective=\"binary:logistic\",\n",
    "                            num_round=10,\n",
    "                            rate_drop=0.3,\n",
    "                            tweedie_variance_power=1.4,\n",
    "                            seed=42,\n",
    "    )\n",
    "    ## How should the algorithm evaluate the model?\n",
    "    objective_metric_name = \"validation:auc\"\n",
    "    \n",
    "    return xgb\n",
    "\n",
    "\n",
    "\n",
    "def fit_model(xgb, s3_input_train, s3_input_test):\n",
    "    \n",
    "    print(f\"{datetime.now(tz).strftime('%H:%M:%S')}: fitting model\", flush=True) ## Print status Message to logs.\n",
    "    \n",
    "    xgb.fit({\"train\": s3_input_train, \"validation\": s3_input_test})#, job_name=job_name)\n",
    "    return xgb\n",
    "\n",
    "\n",
    "\n",
    "# ## check_data_exists\n",
    "# def check_data_exists(train_path, validation_path):\n",
    "#     if not os.path.exists(train_path):\n",
    "#         print(f\"Training data not found at {train_path}\")\n",
    "#     else:\n",
    "#         print(f\"Training data found at {train_path}\")\n",
    "\n",
    "#     if not os.path.exists(validation_path):\n",
    "#         print(f\"Validation data not found at {validation_path}\")\n",
    "#     else:\n",
    "#         print(f\"Validation data found at {validation_path}\")\n",
    "\n",
    "# # Specify your paths\n",
    "# train_path = '/opt/ml/input/data/train'\n",
    "# validation_path = '/opt/ml/input/data/validation'\n",
    "\n",
    "# # Check if data exists at the paths\n",
    "# check_data_exists(train_path, validation_path)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model_and_upload(xgb, validation_data, bucket):\n",
    "    \n",
    "    import boto3\n",
    "    from sklearn.metrics import precision_score, recall_score\n",
    "    from sagemaker.serializers import CSVSerializer\n",
    "    from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "\n",
    "    \n",
    "    X_test = validation_data.drop('target', axis=1)\n",
    "    y_test = validation_data.target\n",
    "    print('length X_test', X_test.shape, flush=True) ## Print shape of data to logs.\n",
    "    print('length y_test', y_test.shape, flush=True)\n",
    "\n",
    "    \n",
    "    # Assuming you have an Estimator object named 'estimator'\n",
    "    # that you used to train your model\n",
    "\n",
    "    # Deploy the trained model to an endpoint\n",
    "    predictor = xgb.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.m4.xlarge',\n",
    "        serializer=CSVSerializer(),\n",
    "        deserializer=CSVDeserializer()\n",
    "    )\n",
    "\n",
    "    # Use the predictor's predict method to make predictions on new data\n",
    "    y_pred = predictor.predict(X_test)\n",
    "    print('length y_pred', len(y_pred), flush=True) ## Print length of y_pred for logs.\n",
    "    \n",
    "    # Convert y_test and y_pred to a common data type\n",
    "    y_test = y_test.astype(float)\n",
    "    y_pred = np.array(y_pred).astype(float)\n",
    "    # Threshold the predicted probabilities to obtain binary predictions\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate the precision and recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print('Precision: ', precision, flush=True) ## Print metrics Messages to logs.\n",
    "    print('Recall ', recall, flush=True)\n",
    "\n",
    "    # Check if the precision and recall are both greater than 0.7\n",
    "    if precision > 0.7 and recall > 0.7:\n",
    "        print(f\"{datetime.now(tz).strftime('%H:%M:%S')}: Model Passed Varification\", flush=True) ## Print status Message to logs.\n",
    "\n",
    "        # Create an S3 client\n",
    "        s3 = boto3.client('s3')\n",
    "\n",
    "        # Set the source and target S3 locations\n",
    "        source_prefix = 'model_dev_pipeline/model_artefacts/'\n",
    "        target_prefix = 'model_artefacts/'\n",
    "\n",
    "        # Copy the latest model artifact from the source S3 location to the target S3 location\n",
    "        copy_latest_model_artifact(s3, bucket, source_prefix, target_prefix)\n",
    "\n",
    "    else:\n",
    "        print(f\"{datetime.now(tz).strftime('%H:%M:%S')}: Model Failed Varification\", flush=True) ## Print status Message to logs.\n",
    "        \n",
    "    ## delete endpoint used for evaluation.\n",
    "    delete_endpoint(predictor)\n",
    "\n",
    "\n",
    "def copy_latest_model_artifact(s3_client, bucket, source_prefix, target_prefix):\n",
    "\n",
    "    # List the folders within the source folder\n",
    "    result = s3_client.list_objects_v2(Bucket=bucket, Prefix=source_prefix, Delimiter='/')\n",
    "    latest_folder = max(result.get('CommonPrefixes', []), key=lambda x: x['Prefix'])\n",
    "\n",
    "    # List the objects within the latest folder\n",
    "    result = s3_client.list_objects_v2(Bucket=bucket, Prefix=latest_folder['Prefix'])\n",
    "    for content in result.get('Contents', []):\n",
    "        # Construct the source and target keys for each object\n",
    "        source_key = content['Key']\n",
    "        print('\\n source key', source_key, flush=True)\n",
    "        target_key = target_prefix + source_key[len(source_prefix):]\n",
    "        print('target key', target_key, flush=True)\n",
    "        # Copy the object from the source S3 location to the target S3 location\n",
    "        s3_client.copy_object(\n",
    "            CopySource={'Bucket': bucket, 'Key': source_key},\n",
    "            Bucket=bucket,\n",
    "            Key=target_key\n",
    "        )\n",
    "\n",
    "    print(f\"{datetime.now(tz).strftime('%H:%M:%S')}: Model Uploaded to S3\", flush=True) ## Print status Message to logs.\n",
    "    \n",
    "def delete_endpoint(predictor):\n",
    "    predictor.delete_endpoint()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "bucket =    'cmg-sagemaker-compliance-cases-data' ## S3 Bucket for training data.\n",
    "prefix =    'training_data'      ## Subfolder in bucket for retrieving training data.\n",
    "file_path = 'temp_training_data' ## Subfolder in bucket for saving temp data and model artefacts.\n",
    "\n",
    "\n",
    "## Get data\n",
    "training_data, testing_data, validation_data = get_data(bucket, prefix, file_path)\n",
    "\n",
    "## Create pointer objects to data in S3\n",
    "s3_input_train, s3_input_test = get_data_pointer(bucket, file_path)\n",
    "\n",
    "## Def model\n",
    "xgb = model(bucket, file_path)\n",
    "\n",
    "## Fit model to data\n",
    "xgb = fit_model(xgb, s3_input_train, s3_input_test )\n",
    "\n",
    "## Evaluate model and if precision and recall both > 0.7, then save to S3.\n",
    "evaluate_model_and_upload(xgb, validation_data, bucket)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
